%\setcounter{chapter}{0}
\chapter{Introduction}
\label{chap:Introduction}

\section{Motivation}
\label{sec:Introduction-Motivation}
% Genuine Waffle (if those who disagree have uncovered this comment I have no regrets)
	The process of music production can be split into four main stages (recording, editing, mixing and mastering) as
	shown in Figure~\ref{fig:MusicProduction}. In the recording stage, acoustic and digital sound sources are captured
	resulting in a set of recorded audio signals (often called stems). These are then edited to correct any mistakes
	made during the recording and to arrange them in time, forming the musical structure of the finished piece. The
	signals are then processed further and mixed together to produce the final product.

	\begin{figure}[h!]
		\centering
		\begin{tikzpicture}
			\node (Sources) [align=center] at (0, 0) {Sound\\Sources};
			\node (Mic1) [draw] at (2, 1.5) {Microphone};
			\node (Mic2) [draw] at (2, 0.5) {Microphone};
			\node (Mic3) [draw] at (2, -0.5) {Microphone};
			\node (Mic4) [draw] at (2, -1.5) {Microphone};

			\draw [dots] (3.2, 3) -- (3.2, -2);
			\node (Recording) at (2, 2.5) {\bf{Recording}};

			\node (Edit1) [draw] at (4.5, 1.5) {Editing Tools};
			\node (Edit2) [draw] at (4.5, 0.5) {Editing Tools};
			\node (Edit3) [draw] at (4.5, -0.5) {Editing Tools};
			\node (Edit4) [draw] at (4.5, -1.5) {Editing Tools};

			\draw (Mic1) -- (Edit1);
			\draw (Mic2) -- (Edit2);
			\draw (Mic3) -- (Edit3);
			\draw (Mic4) -- (Edit4);

			\draw [dots] (5.8, 3) -- (5.8, -2);
			\node (Editing) at (4.5, 2.5) {\bf{Editing}};

			\node (Proc1) [draw] at (6.9, 1.5) {Processing};
			\node (Proc2) [draw] at (6.9, 0.5) {Processing};
			\node (Proc3) [draw] at (6.9, -0.5) {Processing};
			\node (Proc4) [draw] at (6.9, -1.5) {Processing};

			\draw (Edit1) -- (Proc1);
			\draw (Edit2) -- (Proc2);
			\draw (Edit3) -- (Proc3);
			\draw (Edit4) -- (Proc4);

			\node (Mixer) at (9.1, 0) {Mixer};
			\draw (8.2, 1.8) rectangle (10, -1.8);
			\coordinate (Mix1) at (8.2, 1.5);
			\coordinate (Mix2) at (8.2, 0.5);
			\coordinate (Mix3) at (8.2, -0.5);
			\coordinate (Mix4) at (8.2, -1.5);

			\node (Mixing) at (8, 2.5) {\bf{Mixing}};

			\draw (Proc1) -- (Mix1);
			\draw (Proc2) -- (Mix2);
			\draw (Proc3) -- (Mix3);
			\draw (Proc4) -- (Mix4);

			\draw [dots] (10.2, 3) -- (10.2, -2);
			\node (Mastering) at (11.3, 2.5) {\bf{Mastering}};

			\node (Master) [draw] at (11.3, 0) {Processing};
			\draw (10, 0) -- (Master);

			\node (Mix) [align=center] at (13.2, 0) {Finished\\Product};
			\draw (Master) -- (Mix);
		\end{tikzpicture}
		\caption{A block diagram of the music production process.}
		\label{fig:MusicProduction}
	\end{figure}

	During the mixing and mastering stages, audio effects are used to creatively shape the timbre of recorded audio
	signals. This is represented by the blocks labelled ``Processing'' in Figure~\ref{fig:MusicProduction}. This allows
	producers to create timbres which are not possible to achieve through only the recording of acoustic instruments.
	Traditional audio effects evolved from the use of analogue signal processing systems designed to address the
	technical requirements of broadcast or recording. As such, these effects have control parameters which relate
	directly to specific technical properties of an audio signal: a traditional equaliser has parameters for selecting
	specific frequency regions, traditional dynamics processors (compressors and limiters) have parameters relating to
	signal amplitudes. These parameters are effective when correcting technical issues with a signal but do not allow
	for intuitive creative manipulation of timbre.

	The application of audio effects for creative purposes is typically motivated by the perceived timbre of the audio.
	Creative decisions are often expressed using language which does not refer to the mathematical properties of the
	recorded signals. For example, one might ask that the saxophone is made more present in the mix, or that the piano
	be made to sound more airy. In order to complete these tasks using traditional audio effects, music producers and
	audio engineers require knowledge of how the technical parameters of the effect relate to specific perceived aspects
	of timbre. This knowledge is gained through training and experience, presenting an obstacle to novices.

	Audio production software typically uses parameter presets to assist novice users. These are a predefined set of
	parameter values for a particular effect which are labelled with semantic descriptions. Users can apply an effect to
	a signal and choose a preset which best fits their desired outcome. This does not, however, provide an intuitive
	interface to the user. A static parameter setting will not apply the same timbral transformation to all input
	signals. If the user wishes to alter the settings slightly, they still require knowledge of how the effect's
	parameters relate to perceived timbre. For example, a user might apply a preset to make a sound brighter, if they
	are not happy with the result no assistance is given in making the sound more or less bright.

	More intuitive interfaces for control over timbre provide parameters which directly relate to perceived aspects of a
	sound. These perform the translation between the language used to describe timbre and the technical parameters of
	signal processing algorithms, allowing users to focus on the creative aspects of music production. Having timbral
	properties controlled by continuous parameters increases the intuitiveness of the system as it is evident which
	parameter to adjust to change a particular timbral property. The effect can also analyse the input signal and adjust
	itself such that the parameter has similar timbral effects across a wide range of inputs. Developing this type of
	semantically controlled effect requires study of how the mathematical properties of a signal contribute to its
	perceived timbre. Effects can then be built which manipulate these signal properties according to the value of a
	semantically labelled parameter. Making audio effects more intuitive in this manner aids both novice and experienced
	music producers and audio engineers. Novices benefit from the reduced amount of knowledge needed to apply audio
	effects; being able to select and adjust effects based on natural language descriptions of timbre rather than
	requiring a technical knowledge of signal processing. For experienced users these effects can be used to accelerate
	the production process; reducing the work required to configure audio effect parameters, allowing users to focus on
	creative decisions. 
	
	Commercial audio effects with semantically labelled parameters have been available for a number of years, for
	example the OneKnob series of effects produced by \citet{wavesoneknob}. Being commercial products, the operation of
	these effects is not known, but it is assumed that they were developed alongside input from professional audio
	engineers. In academic research, a number of studies have been undertaken in developing these types of control
	systems for synthesis and audio processing applications (discussed in Section~\ref{sec:Timbre-Control}). This work
	focusses on how this type of system can be built using nonlinear distortion / excitation effects.

\section{Objectives and Research Questions}
\label{sec:Introduction-Objectives}
	The underlying objective of this thesis is to produce intuitive timbre shaping effects based on harmonic excitation
	algorithms (systems which introduce new harmonic partials to a signal). This is achieved through answering the
	following questions:

	\begin{itemize}
		\item What semantic terms are commonly used to describe the timbre of harmonic excitation effects? 
		\item What properties of audio signals contribute to these timbral descriptions and what alterations are
		      made to signals to produce a certain timbral result?
		\item What properties of audio signals can be reliably controlled by harmonic excitation algorithms?
		\item How can harmonic excitation systems be configured to control elements of timbre? Systems will be
		      proposed which allow control over particular semantic features and the accuracy of these systems
		      assessed.
		\item Can harmonic excitation be used to provide intuitive control of timbre? Do the proposed systems
		      provide control over the aspects of timbre they are designed to?
	\end{itemize}

\section{Thesis Structure}
\label{sec:Introduction-ThesisStructure}
	The aim of this work is to develop harmonic excitation systems which provide intuitive control over timbre.
	Firstly, a review of the existing work in timbral manipulation and nonlinear processing is given. Experiments are
	then conducted to discover how spectral manipulations are used in music production. This information is used to aid
	in the design of semantically controlled harmonic excitation effects which are subsequently evaluated in perceptual
	listening tests. This is presented in seven chapters as follows:

	In {\bf{Chapter~\ref{chap:Timbre}}} the background of research into timbre is discussed. It begins with a discussion
	of the low level features of audio signals. Popular experimental methodologies for uncovering the perceptual effects
	of these features are then introduced along with the methods used to analyse their results. Finally, existing work
	concerning the control of perceptual features of audio signals is discussed.

	{\bf{Chapter~\ref{chap:Excitation}}} covers the body of work concerning harmonic excitation, starting with a
	discussion of the analysis of nonlinear systems in the field of audio production. The uses of such systems and the
	their timbral effects are then presented. Finally, various algorithms for harmonic excitation, proposed in existing
	literature, are described.

	In {\bf{Chapter~\ref{chap:TimbreEvaluation}}} the collection of semantic audio data during the music production
	process is discussed. This data is used to determine the language used for describing audio in a studio environment
	and how audio effects are used to evoke certain timbral descriptors.

	In {\bf{Chapter~\ref{chap:ExcitationEvaluation}}} a set of criteria for assessing the applicability of harmonic
	excitation techniques to timbral control is proposed. The algorithms described in Chapter~\ref{chap:Excitation} are
	then evaluated against these criteria to identify those most suitable for use in timbral control systems.  Methods
	by which the performance of certain harmonic excitation methods can be improved are proposed.

	In {\bf{Chapter~\ref{chap:FeatureControl}}}, results from Chapter~\ref{chap:ExcitationEvaluation} are used to inform
	the design of systems for controlling low level features using harmonic excitation techniques. Systems are developed
	which can be used to provide monotonic control over a specific low level feature of the input signal. The operation
	of these systems is evaluated using a number of test signals.

	In {\bf{Chapter~\ref{chap:PerceptualExperiments}}} the systems proposed in Chapter~\ref{chap:FeatureControl} are
	refined, using the results of Chapter~\ref{chap:TimbreEvaluation}, to develop harmonic excitation effects which
	control specific timbral traits of a signal. These effects are evaluated objectively, through comparison with the
	dataset gathered in Chapter~\ref{chap:TimbreEvaluation}; and subjectively, through a series of perceptual listening
	tests.

	We conclude in {\bf{Chapter~\ref{chap:Conclusion}}} with a summary of findings across Chapters
	\ref{chap:TimbreEvaluation} to \ref{chap:PerceptualExperiments}, a critique of the methods used in this work and
	suggestions for further work in this area.

\section{Contributions}
\label{sec:Introduction-Contributions}
	The primary contribution of this thesis is the proposal of methods by which harmonic excitation systems can be
	configured to give intuitive control over timbral features. In achieving this a number of other contributions are
	made, as follows:

	\begin{itemize}
		\item A new method for the collection of semantic audio descriptors and their underlying features
		      (Chapter~\ref{chap:TimbreEvaluation}).
		\item A new metric for the measurement of agreement in multidimensional distributions
		      (Chapter~\ref{chap:TimbreEvaluation}).
		\item A methodology for the assessment of harmonic generation algorithms for use in timbral control
		      (Chapter~\ref{chap:ExcitationEvaluation}).
		\item A comparison of harmonic generation algorithms and their suitability to provide perceptual control
		      (Chapter~\ref{chap:ExcitationEvaluation}).
		\item The development of new harmonic excitation systems for control of low level audio features
		      (Chapter~\ref{chap:FeatureControl}).
		\item New methods for controlling perceptual attributes using harmonic excitation
		      (Chapter~\ref{chap:PerceptualExperiments}).
	\end{itemize}

	The following papers have been published as part of this work:

	\begin{itemize}
		\item \bibentry{enderby2012harmonic}.
		\item \bibentry{enderby2013methods}.
		\item \bibentry{stables2014safe}.
		\item Enderby, S. and Stables, R. (September 2017), A Nonlinear Method for Manipulating Warmth and
		      Brightness, in \emph{Proceedings of the International Conference on Digital Audio Effects (DAFx-17)}.
	\end{itemize}

	Other associated publications include:

	\begin{itemize}
		\item Ward, D., Enderby, S., Athwal, C. and Reiss, J. (December 2015), Real-Time Excitation Based Binaural
		      Loudness Meters, in \emph{Proceedings of the International Conference on Digital Audio Effects
		      (DAFx-15)}.
		\item Stables, R., De Man, B., Enderby, S., Reiss, J., Fazekas, G. and Wilmering, T. (October 2016),
		      Semantic Description of Timbral Transformations in Music Production, in \emph{Proceedings of the
		      2016 ACM on Multimedia Conference}.
		\item Stasis, S., Jillings, N., Enderby, S. and Stables, R. (September 2017), Audio Processing Chain
		      Recommendation, in \emph{Proceedings of the International Conference on Digital Audio Effects
		      (DAFx-17)}.
	\end{itemize}
